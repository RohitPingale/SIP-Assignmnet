{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hheee\n",
      "it's dimensions are(512, 512, 3)\n",
      "size of test arrray is(512, 512)\n",
      "band shape is(514, 514)\n",
      "Enter the size of the filter you want3\n",
      "Filter size is3\n",
      "total_elements are262144\n",
      "Please enter the value of P (enter between 0-1)0.6\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"int\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-89c80df88f35>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrimmed_Mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"lenna.png\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m \u001b[0mlocation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mImage_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;31m#print(location.image_location)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-89c80df88f35>\u001b[0m in \u001b[0;36mImage_read\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_printoptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[1;31m#print(img[0])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-89c80df88f35>\u001b[0m in \u001b[0;36mfilter_size\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mimageBand\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimagePadding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestarray\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpaddingValue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-89c80df88f35>\u001b[0m in \u001b[0;36mimagePadding\u001b[1;34m(self, band, paddingValue)\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[1;31m#print(type(band))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m         \u001b[1;31m#print(band[0])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_convolution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mband\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpaddingValue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mImage_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-89c80df88f35>\u001b[0m in \u001b[0;36mimage_convolution\u001b[1;34m(self, testarray, paddingValue)\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[1;31m#self.image_convolution_step2(img_sampling,height,width,filter_size1,paddingValue)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradient_inverse_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_sampling\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfilter_size1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpaddingValue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mGradient_inverse_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimg_sampling\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfilter_size1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpaddingValue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-89c80df88f35>\u001b[0m in \u001b[0;36mGradient_inverse_filter\u001b[1;34m(self, img_sampling, height, width, filter_size1, paddingValue)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"count is\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m                 \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate str (not \"int\") to str"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "\n",
    "class trimmed_Mean:\n",
    "    def __init__(self,image):\n",
    "        self.image_location=image\n",
    "        print(\"hheee\")\n",
    "        \n",
    "    \n",
    "    def filter_size(self,image):\n",
    "        paddingValue = int((3 - 1)/2)  #values have been hardcoded so check properly\n",
    "        testarray =  np.array([array[:,0] for array in image])\n",
    "        print(\"size of test arrray is\"+str(testarray.shape))\n",
    "        #print(testarray[0])\n",
    "        #print(testarray[1])\n",
    "        \n",
    "      \n",
    "        \n",
    "        imageBand = self.imagePadding(testarray,paddingValue)\n",
    "        \n",
    "        \n",
    "    def image_convolution(self,testarray,paddingValue):\n",
    "        height=testarray.shape[0]\n",
    "        width=testarray.shape[1]\n",
    "        mega_matrix=[]\n",
    "        \n",
    "        filter_size1=int(input(\"Enter the size of the filter you want\"))\n",
    "        print(\"Filter size is\"+str(filter_size1))\n",
    "        \n",
    "        for i in range(0, height - filter_size1 + 1):\n",
    "            for j in range(0, width - filter_size1 + 1):\n",
    "                mega_matrix.append(\n",
    "                    [\n",
    "                        [testarray[col][row] for row in range(j, j + filter_size1)]\n",
    "                        for col in range(i, i + filter_size1)\n",
    "                    ]\n",
    "                                   )\n",
    "        img_sampling = np.array(mega_matrix)\n",
    "        #print(img_sampling.shape)\n",
    "        #self.image_convolution_step2(img_sampling,height,width,filter_size1,paddingValue)\n",
    "        \n",
    "        self.Gradient_inverse_filter(img_sampling,height,width,filter_size1,paddingValue)\n",
    "        \n",
    "    def Gradient_inverse_filter(self,img_sampling,height,width,filter_size1,paddingValue):\n",
    "        org_height=height-(paddingValue*2)\n",
    "        org_width=width-(paddingValue*2)\n",
    "        \n",
    "        total_elements=org_height*org_width\n",
    "        print(\"total_elements are\"+str(total_elements))\n",
    "        #considering only one matrix from image\n",
    "        l1=[]\n",
    "        new_image1=[]\n",
    "        count=0\n",
    "        \n",
    "        value_of_p=float(input(\"Please enter the value of P (enter between 0-1)\"))\n",
    "        rem_pixels_val=(1-value_of_p)/8\n",
    "            \n",
    "        for k in range(0,total_elements):\n",
    "            for i in range(0,filter_size1):\n",
    "                for j in range(0,filter_size1):\n",
    "                    #print(img_sampling[0][i][j])\n",
    "                    l1.append(img_sampling[k][i][j])\n",
    "                    \n",
    "               \n",
    "            \n",
    "            \n",
    "            count=count+1\n",
    "            print(\"count is\"+str(count))\n",
    "            for i in range(0,len(l1)):\n",
    "                if(i==4):\n",
    "                    l1[i]=l1[i]*value_of_p\n",
    "                else:\n",
    "                    l1[i]=l1[i]*rem_pixels_val\n",
    "            \n",
    "            sum=0\n",
    "            for i in range(0,len(l1)):\n",
    "                sum=sum+l1[i]\n",
    "            \n",
    "            new_image1.append(sum)\n",
    "            #print(new_image)\n",
    "        \n",
    "        \n",
    "        #new_transform=np.array(new_image1).reshape(org_height,org_width)\n",
    "        #print(new_transform.shape)\n",
    "        #cv2.imwrite(str('aniket11'+'.'+'jpg'),new_transform)\n",
    "        print(\"end..........\")        \n",
    "            \n",
    "            \n",
    "        \n",
    "    def image_convolution_step2(self,img_sampling,height,width,filter_size1,paddingValue):\n",
    "        #print(img_sampling)\n",
    "        #print(img_sampling[0])\n",
    "        #print(img_sampling[0][0])\n",
    "        #print(img_sampling[0])\n",
    "        print(\"hellooooooo\")\n",
    "        \n",
    "        org_height=height-(paddingValue*2)\n",
    "        org_width=width-(paddingValue*2)\n",
    "        \n",
    "        total_elements=org_height*org_width\n",
    "        print(\"total_elements are\"+str(total_elements))\n",
    "        \n",
    "        #considering only one matrix from image\n",
    "        l1=[]\n",
    "        new_image=[]\n",
    "        l2=[]\n",
    "        \n",
    "        \n",
    "        for k in range(0,total_elements):\n",
    "            for i in range(0,filter_size1):\n",
    "                for j in range(0,filter_size1):\n",
    "                    #print(img_sampling[0][i][j])\n",
    "                    l1.append(img_sampling[k][i][j])\n",
    "                    \n",
    "               \n",
    "            l1.sort()\n",
    "            #suppose here i am taking k as 2 (two highest element and 2 smallest element)\n",
    "            #total elements in filter=k*k (3*3=9)\n",
    "            mean=(1/(9-4)) #(4 elements to be deleted)  here mean is hardcoded need to change later\n",
    "            #print(\"mean\")\n",
    "            #print(mean)\n",
    "        \n",
    "            #print(l1)\n",
    "        \n",
    "            \n",
    "            for i in range(2,7):\n",
    "                l2.append(l1[i])\n",
    "            #print(l2)\n",
    "            l1.clear()\n",
    "        \n",
    "            sum=0\n",
    "            for i in range(0,len(l2)):\n",
    "                sum=sum+(mean*l2[i])\n",
    "            \n",
    "            sum=math.ceil(sum)\n",
    "            l2.clear()\n",
    "        \n",
    "            \n",
    "            new_image.append(sum)\n",
    "        #print(new_image)\n",
    "        new_transform=np.array(new_image).reshape(org_height,org_width)\n",
    "        print(new_transform.shape)\n",
    "        cv2.imwrite(str('aniket'+'.'+'jpg'),new_transform)\n",
    "        print(\"end..........\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def imagePadding(self,band,paddingValue):\n",
    "        ##vertical Top padding\n",
    "        band = np.insert(band,0,band[0]*np.ones(paddingValue)[:,None],axis = 0)\n",
    "        ##vertical bottom padding\n",
    "        band =  np.insert(band,len(band),band[-1]*np.ones(paddingValue)[:,None],axis = 0)\n",
    "        ##Horizontal left padding\n",
    "        band = np.insert(band, 0, band[:,0]*np.ones(paddingValue)[:,None], axis=1)\n",
    "        ##Horizontal right padding\n",
    "        band = np.insert(band, len(band[0]), band[:,-1]*np.ones(paddingValue)[:,None], axis=1)\n",
    "        print(\"band shape is\"+str(band.shape))\n",
    "        #np.set_printoptions(threshold=np.inf)\n",
    "        #print(band)\n",
    "        #print(type(band))\n",
    "        #print(band[0])\n",
    "        self.image_convolution(band,paddingValue)\n",
    "        \n",
    "    def Image_read(self):\n",
    "        img=cv2.imread(location.image_location,cv2.IMREAD_UNCHANGED)\n",
    "        dimensions=img.shape\n",
    "        print(\"it's dimensions are\"+str(dimensions))\n",
    "        np.set_printoptions(threshold=np.inf)\n",
    "        #print(img[0])\n",
    "        self.filter_size(img)\n",
    "    \n",
    "        \n",
    "       \n",
    "        \n",
    "        \n",
    "location=trimmed_Mean(\"lenna.png\")\n",
    "location.Image_read()\n",
    "#print(location.image_location)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
